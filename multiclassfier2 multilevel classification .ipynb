{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d905e765",
   "metadata": {},
   "source": [
    "# multilevel classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aa62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5473f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484489b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAD30lEQVR4nO3dQVErSwCG0c4rBERCHBALcYAEHIAEJIATcICExEFQQBzMW91diru59HxQ5ywzi7+L5KupYtObZVkG0PPf2gcArhMnRIkTosQJUeKEqJu/PJ/2r9zj8Thratzf30/bGmOM0+k0bevh4WHa1vPz87StX25z7UNvTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Rt/nJ57rTrGGZekfD6+jpta4wxdrvdtK3z+Txta+YVGjP/hitwHQP8JOKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqMx1DNvtdtbU9OsYZjocDtO2Pj8/p23N/H2swHUM8JOIE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVE3ax/gj8vlsvYRvs3b29vaR/gWM7+zX35XylXenBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTojaLMvy1fMvH/5Us69+2O/307ZmXltwPB6nbf1ym2sfenNClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDgh6mbtA6zh8fFx6t7Hx8e0rZeXl2lbfC9vTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0RtlmX56vmXD/+l9/f3WVPjcDhM2xpjjNvb22lbd3d307bO5/O0re12O21rjDGenp6mbW232821z705IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiLpZ+wB/7Ha7tY/wbU6n07Sty+UybWvmd7bf76dtVXhzQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWqzLMvaZwCu8OaEKHFClDghSpwQJU6IEidE/Q9FTVPbsnzhHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X_train[0]\n",
    "some_digit_image = some_digit.reshape(8,8)\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304dcea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "551e4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make multiclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6ed7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier   #automatically runs OvA \n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "\n",
    "sgd_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c93eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5798.49283312, -4095.80353671,  3702.1556573 , -1516.98373125,\n",
       "        -5039.24614592, -2814.92740216, -4655.66188935, -2524.83588306,\n",
       "        -1751.57920211, -2617.2552933 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d94b6453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e76f055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbf32f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b740085",
   "metadata": {},
   "source": [
    "1. If you want to force ScikitLearn to use one-versus-one or one-versus-all, you can use\n",
    "the OneVsOneClassifier or OneVsRestClassifier classes. \n",
    "2. Simply create an instance\n",
    "and pass a binary classifier to its constructor. \n",
    "\n",
    "3. For example, this code creates a multi‚Äê\n",
    "class classifier using the OvO strategy, based on a SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240f9b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ovo\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0207b8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ovo_clf.estimators_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "693557f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomforest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd101d8",
   "metadata": {},
   "source": [
    "Scikit-Learn did not have to run OvA or OvO because Random Forest\n",
    "classifiers can directly classify instances into multiple classes.\n",
    "\n",
    "predict_proba() to get the list of probabilities that the classifier assigned to each\n",
    "instance for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d4d3359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.01, 0.96, 0.  , 0.  , 0.01, 0.01, 0.  , 0.01, 0.  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_prob  =  forest_clf.predict_proba([some_digit])\n",
    "some_digit_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a630de",
   "metadata": {},
   "source": [
    "the classifier is fairly confident about its prediction: the 0.96 at the 2th\n",
    "index in the array means that the model estimates a 96% probability that the image\n",
    "represents a 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472295ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(some_digit_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc429a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.classes_[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b95ca",
   "metadata": {},
   "source": [
    "# evaluate these classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ad846f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487750556792873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.93541203, 0.94877506, 0.96213808])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score1 = cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(np.mean(score1))\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54164c",
   "metadata": {},
   "source": [
    "it gets over 93% on all test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f575e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487750556792873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9532294 , 0.93541203, 0.95768374])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "score = cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n",
    "print(np.mean(score))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c8a1f2",
   "metadata": {},
   "source": [
    "scaleing doesnt effect much to the test accuracy as did in books example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ede9f0",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "196667c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbae4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train,y_train,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ee4a31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,   0,   0,   0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0, 130,   0,   2,   1,   0,   2,   0,   3,   1],\n",
       "       [  0,   2, 129,   1,   0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0, 127,   0,   5,   0,   2,   3,   1],\n",
       "       [  0,   0,   0,   0, 140,   0,   0,   0,   3,   0],\n",
       "       [  0,   1,   0,   1,   0, 128,   1,   1,   0,   2],\n",
       "       [  0,   1,   0,   0,   1,   1, 125,   0,   1,   0],\n",
       "       [  0,   0,   0,   2,   0,   0,   0, 127,   1,   1],\n",
       "       [  0,   7,   0,   3,   1,   1,   2,   0, 111,   1],\n",
       "       [  0,   2,   0,   4,   0,   0,   0,   1,   5, 121]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "con_mtrx = confusion_matrix(y_train, y_train_pred)\n",
    "con_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "552ee29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f54d2",
   "metadata": {},
   "source": [
    "That‚Äôs a lot of numbers. It‚Äôs often more convenient to look at an image representation\n",
    "of the confusion matrix, using Matplotlib‚Äôs matshow() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be4aaf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (20,20))\n",
    "plt.matshow(con_mtrx, cmap = plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "#rows represent actual classes, while columns represent predicted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c77122",
   "metadata": {},
   "source": [
    "This confusion matrix looks fairly good, since most images are on the main diagonal,\n",
    "which means that they were classified correctly. \n",
    "\n",
    "The 8s look slightly darker than the\n",
    "other digits, which could mean that there are fewer images of 8s in the dataset or that\n",
    "the classifier does not perform as well on 8s as on other digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a3bf3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    143\n",
       "0    141\n",
       "1    139\n",
       "3    138\n",
       "5    134\n",
       "2    133\n",
       "9    133\n",
       "7    131\n",
       "6    129\n",
       "8    126\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.DataFrame(X_train )\n",
    "df['y'] = y_train\n",
    "df.y .value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc0f76",
   "metadata": {},
   "source": [
    "Let‚Äôs focus the plot on the errors. \n",
    "\n",
    "First, you need to divide each value in the confusion\n",
    "matrix by the number of images in the corresponding class, so you can compare errorrates instead of absolute number of errors ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0b3c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9929078  0.         0.        ]\n",
      " [0.         0.9352518  0.        ]\n",
      " [0.         0.01503759 0.96992481]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9929078 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0070922 , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9352518 , 0.        , 0.01438849, 0.00719424,\n",
       "        0.        , 0.01438849, 0.        , 0.02158273, 0.00719424],\n",
       "       [0.        , 0.01503759, 0.96992481, 0.0075188 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0075188 ],\n",
       "       [0.        , 0.        , 0.        , 0.92028986, 0.        ,\n",
       "        0.03623188, 0.        , 0.01449275, 0.02173913, 0.00724638],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.97902098,\n",
       "        0.        , 0.        , 0.        , 0.02097902, 0.        ],\n",
       "       [0.        , 0.00746269, 0.        , 0.00746269, 0.        ,\n",
       "        0.95522388, 0.00746269, 0.00746269, 0.        , 0.01492537],\n",
       "       [0.        , 0.00775194, 0.        , 0.        , 0.00775194,\n",
       "        0.00775194, 0.96899225, 0.        , 0.00775194, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.01526718, 0.        ,\n",
       "        0.        , 0.        , 0.96946565, 0.00763359, 0.00763359],\n",
       "       [0.        , 0.05555556, 0.        , 0.02380952, 0.00793651,\n",
       "        0.00793651, 0.01587302, 0.        , 0.88095238, 0.00793651],\n",
       "       [0.        , 0.01503759, 0.        , 0.03007519, 0.        ,\n",
       "        0.        , 0.        , 0.0075188 , 0.03759398, 0.90977444]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums = con_mtrx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = con_mtrx / row_sums\n",
    "print(norm_conf_mx[:3,:3])\n",
    "norm_conf_mx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa83151d",
   "metadata": {},
   "source": [
    "Now let‚Äôs fill the diagonal with zeros to keep only the errors, and let‚Äôs plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef5264fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.01503759 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "print(norm_conf_mx[:3,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "df2496f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc48e02",
   "metadata": {},
   "source": [
    "in book example fig\n",
    "\n",
    "\n",
    "Now you can clearly see the kinds of errors the classifier makes. Remember that rows\n",
    "represent actual classes, while columns represent predicted classes. The column for\n",
    "class 8 is quite bright, which tells you that many images get misclassified as 8s. \n",
    "\n",
    "How‚Äê\n",
    "ever, the row for class 8 is not that bad, telling you that actual 8s in general get prop‚Äê\n",
    "erly classified as 8s. \n",
    "\n",
    "As you can see, the confusion matrix is not necessarily\n",
    "symmetrical. You can also see that 3s and 5s often get confused (in both directions).\n",
    "Analyzing the confusion matrix can often give you insights on ways to improve your\n",
    "classifier. Looking at this plot, it seems that your efforts should be spent on reducing\n",
    "the false 8s.\n",
    "\n",
    "fig - link \n",
    "file:///E:/books/2-Aur%C3%A9lien-G%C3%A9ron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-O%E2%80%99Reilly-Media-2019.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198695a1",
   "metadata": {},
   "source": [
    "# Multilabel Classi¬Äcation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dad5fa",
   "metadata": {},
   "source": [
    "1. want your classifier to output multiple classes for each instance.\n",
    "\n",
    "2. face-recognition classifier: what should it do if it recognizes several people\n",
    "on the same picture\n",
    "\n",
    "3. recognize three faces, Alice, Bob, and Charlie;\n",
    "when it is shown a picture of Alice and Charlie, it should output [1, 0, 1]\n",
    "4. Such a classification system that outputs multiple\n",
    "binary tags is called a multilabel classification system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad141c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c677c3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False],\n",
       "       [ True, False],\n",
       "       [ True,  True],\n",
       "       ...,\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82868262",
   "metadata": {},
   "source": [
    "1. This code creates a y_multilabel array containing two target labels for each digit\n",
    "image: \n",
    "2. the first indicates whether or not the digit is large (7, 8, or 9) and \n",
    "3. the second\n",
    "indicates whether or not it is odd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "61100af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e7115a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb4f7011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some_digit= X_train[0]\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aef41a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True,  True]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let \n",
    "some_digit1= X_train[7]\n",
    "print(y_train[7])\n",
    "knn_clf.predict([some_digit1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e23596d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b7cb4",
   "metadata": {},
   "source": [
    "one approach is to measure the F1\n",
    " score\n",
    "for each individual label (or any other binary classifier metric discussed earlier), then\n",
    "simply compute the average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fd4b1c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9820990302926285"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4621b",
   "metadata": {},
   "source": [
    "This assumes that all labels are equally important, which may not be the case. \n",
    "\n",
    "In par‚Äê\n",
    "ticular, if you have many more pictures of Alice than of Bob or Charlie, you may want\n",
    "to give more weight to the classifier‚Äôs score on pictures of Alice. One simple option is\n",
    "to give each label a weight equal to its support (i.e., the number of instances with that\n",
    "target label). To do this, simply set average=\"weighted\" in the preceding code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9adfb12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835320167810259"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "\n",
    "f1_score(y_multilabel, y_train_knn_pred,  average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8e3f36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784706755753526"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_multilabel, y_train_knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29974caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
